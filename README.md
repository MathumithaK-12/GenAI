✅ 23rd july
Invoking a model (LlaMA) by inferencing using groq api

steps
1. Prompted in ChatGPT to get the code for inferencing using groq

Prompt -
How to Invoke a model in google collab  using groq api

2. create a api key in groq
https://console.groq.com

3. Used the code by embedding the key from groq in Google collab



✅ 24th july

Use case preparation
AI support analyst for CMS pack failures

The AI agent should raise a incident based on the user information like order id and container id 

If the cms error response is known the agent will respond with reason and close the log

If the agent is unaware of the error, it should be invoking the email to the team IT with the incident details



Prompt used

Say we are creating a new ai chat agent model for remedy style itsm

Consider a rookie is trying this and want to use open source llms , groq for inferencing and google colab 

Also wanted to create a synthetic data using faker for implementing this

Create a synthetic data with order id container id timestamp and error response from cms including both positive and negative response for around 500 records

Also tell how to train or fine the model which are building now using unsloth

Finally also include a script to invoke a mail to it team when the error reason is not found

Give a detailed step by by step procedure to achieve the end goal


If the user just says they are facing issue with printing
But not given any order id or container 
Will the agent ask for the details


✅ 27 July 2025
Implementing github actions for Inference of LlaMa model using Groq API 
1. Add the python script for inferencing the LlaMa model using Groq.
   1.1 The output should be saved in a file
   -> Path to python code - https://github.com/MathumithaK-12/GenAI/blob/main/inference_groq_2.py
2. Create GitHub Actions Workflow
   2.1 The action will be triggered only if there is push to the python script
   2.2 Or the action is triggered manually
   2.3 The output will be stored as downloadable (.zip) file in the artifact
   -> Path to yml file - https://github.com/MathumithaK-12/GenAI/blob/main/.github/workflows/groq-inference.yml
3. Add Secret to GitHub
   3.1 - Go to your repository → Settings → Secrets and variables → Actions
   3.2 - Click New repository secret
         Name: GROQ_API_KEY
         Value: your actual Groq API key
4. Trigger the Workflow
   4.1 Go to the Actions tab in GitHub
   4.2 Select "Run Groq Inference"
   4.3 Click "Run workflow"
5. After a successful run, scroll to the bottom of the latest run and Download the artifact groq-result, which will contain your Groq output.
   -> Path to the sample output of the prompt (Write a user requirement for password reset.) - https://github.com/MathumithaK-12/GenAI/blob/main/groq-result/groq_output.txt



✅ 27 July 2025 
Use Case - AI powered ITSM Analyst 

Purpose
 -> Identify known printing errors
 -> Respond with appropriate workarounds
 -> Request missing information (like order ID, container ID)
 -> Log unknown incidents with incident IDs 
 -> Trigger mail to the IT team with the required information
 -> Allow users to check the status of previously logged incidents
 
Key Features
1. Known Error Response
	•	Agent identifies known issues from the knowledge base.
	•	Returns appropriate workaround instantly.

2. Missing Info Extraction
	•	If order ID or container ID is missing, the agent prompts user for it.

3. Unknown Incident Logging
	•	Logs an incident with an autogenerated ID like INC-20250727-002.
	•	Stores it with issue details and timestamp.
	•	Marks status as Open.

4. Incident Status Checking
	•	If user provides an incident ID, the agent returns:
	•	Status (Open, In Progress, Resolved, Closed)
	•	Workaround if available
	•	Timestamps

5. Email Alert to IT Team
	•	When an unknown issue is logged, the agent:
	•	Composes and sends an email to the IT support group.
	•	Email includes: order ID, container ID, issue description, timestamp, and incident ID.

 


